"""
These tests evaluate Plot* functions, write the result expression to a file in
outline tree form, and then compare the actual result with an expected reference
result using diff. For example, if the code that emits a PlotRange based on
the actual range of data plotted is disabled, the diff looks like this,
making it fairly clear what is wrong:

@@ -109,13 +109,7 @@
     System`None
   System`Rule
     System`PlotRange
-    System`List
-      System`List
-        System`Real 0.0
-        System`Real 1.0
-      System`List
-        System`Real 0.0
-        System`Real 1.0
+    System`Automatic
   System`Rule
     System`PlotRangeClipping
     System`False

The NumericArrays are emitted using NumPy's default str, which is an
abbreviated display of the array, which has enough data that it should
generally catch any gross error. For example if the function being
plotted is changed the diff shows that the the of the array is correct,
but the xyz coordinates output points are changed:

@@ -7,12 +7,12 @@
     System`GraphicsComplex
       System`NumericArray NumericArray[Real64, 40000×3]
         [[0.         0.         0.        ]
-         [0.00502513 0.         0.        ]
-         [0.01005025 0.         0.        ]
+         [0.00502513 0.         0.00502513]
+         [0.01005025 0.         0.01005025]
          ...
-         [0.98994975 1.         0.98994975]
-         [0.99497487 1.         0.99497487]
-         [1.         1.         1.        ]]
+         [0.98994975 1.         1.98994975]
+         [0.99497487 1.         1.99497487]
+         [1.         1.         2.        ]]
       System`Polygon
         System`NumericArray NumericArray[Integer64, 39601×4]
           [[    1     2   202   201]

The reference results are not huge but they are too unwieldy
to include in code, so they are stored as files in their own
*_ref directory.
"""

import os
import subprocess
from test.helper import session

import mathics.builtin.drawing.plot as plot
from mathics.core.util import print_expression_tree

both = [
    ("test-plot3d", "Plot3D[x y, {x,0,1}, {y,0,1}]"),
]

classic = [
    ("test-plot", "Plot[x, {x,0,1}]"),
]

vectorized = [
    ("test-density", "DensityPlot[x y, {x,0,1}, {y,0,1}]"),
]


def ref_dir():
    dir, _ = os.path.splitext(__file__)
    return dir + "_ref"


def one_test(name, str_expr, act_dir="/tmp"):
    print(f"=== running {name} {str_expr}")

    # evaluate the expression to be tested
    expr = session.parse(str_expr)
    act_expr = expr.evaluate(session.evaluation)

    # write the results to act_fn in act_dir
    act_fn = os.path.join(act_dir, f"{name}.txt")
    with open(act_fn, "w") as act_f:
        print_expression_tree(act_expr, file=act_f)

    # use diff to compare the actual result in act_fn to reference result in ref_fn

    ref_fn = os.path.join(ref_dir(), f"{name}.txt")
    result = subprocess.run(["diff", "-u", ref_fn, act_fn], capture_output=False)
    assert result.returncode == 0, "reference and actual output differ"


def test_all(act_dir="/tmp"):
    # run vectorized tests
    try:
        plot.use_vectorized_plot = True
        for name, str_expr in vectorized + both:
            one_test(name + "-vectorized", str_expr, act_dir)
    finally:
        plot.use_vectorized_plot = False

    # run classic tests
    for name, str_expr in classic + both:
        one_test(name, str_expr, act_dir)


if __name__ == "__main__":
    # reference files can be generated by pointing saved actual
    # output at reference dir instead of /tmp
    def make_ref_files():
        test_all(ref_dir())

    def run_tests():
        try:
            test_all()
        except AssertionError:
            print("FAIL")

    # make_ref_files()
    run_tests()
